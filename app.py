import os
import json
from datetime import datetime
import streamlit as st
import pandas as pd
st.write("RUNNING FROM:", os.path.abspath(__file__))
st.write("LAST MOD:", os.path.getmtime(__file__))
from tools import (
    read_table,
    normalize_columns,
    compute_weekly_kpis,
    dataframe_to_markdown_table,
    load_skill_pack,
    call_ollama_chat,
    build_report_prompt,
    make_docx_from_markdown_text,
)

st.set_page_config(page_title="Skills Demo | é¡¹ç›®å‘¨æŠ¥ç”Ÿæˆå™¨", layout="wide")

st.title("ğŸ§© Skills Demoï¼šé¡¹ç›®å‘¨æŠ¥ç”Ÿæˆå™¨ï¼ˆæœ¬åœ°æ¨¡å‹ + Ollamaï¼‰")

# ---- Sidebar: config ----
st.sidebar.header("é…ç½®")
ollama_host = st.sidebar.text_input("Ollama Host", value=os.getenv("OLLAMA_HOST", "http://127.0.0.1:11434"))
ollama_model = st.sidebar.text_input("Ollama Model", value=os.getenv("OLLAMA_MODEL", "qwen3:14b"))
temperature = st.sidebar.slider("temperature", 0.0, 1.5, 0.3, 0.05)

st.sidebar.divider()
st.sidebar.header("Skillï¼ˆæŠ€èƒ½åŒ…ï¼‰")
skill_name = st.sidebar.selectbox("é€‰æ‹© Skill", ["None", "weekly_report"])

st.sidebar.caption("æç¤ºï¼šSkills çš„æœ¬è´¨æ˜¯æŠŠ SOP + æ¨¡æ¿ + å£å¾„å›ºåŒ–ä¸ºå¯æ’æ‹”æ¨¡å—ã€‚")
st.sidebar.divider()
show_trace = st.sidebar.checkbox("æ˜¾ç¤ºæ‰§è¡Œè½¨è¿¹", value=True)

# ---- Upload ----
colL, colR = st.columns([1, 1])
with colL:
    st.subheader("1) ä¸Šä¼ ä»»åŠ¡æ¸…å•ï¼ˆExcel / CSVï¼‰")
    file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", type=["xlsx", "xls", "csv"])
    st.caption("å»ºè®®åˆ—ï¼šproject / module / owner / status / priority / due_date / progress / blocker / risk")

# ---- Read & preview ----
trace = []
df = None
if file is not None:
    trace.append(f"Loaded file: {file.name}")
    df = read_table(file)
    trace.append(f"Parsed rows: {len(df)}")

    df = normalize_columns(df)
    trace.append("Normalized columns")

    with colL:
        st.write("æ•°æ®é¢„è§ˆï¼ˆå‰ 50 è¡Œï¼‰")
        st.dataframe(df.head(50), width=True)

# ---- Generate report ----
with colR:
    st.subheader("2) ç”Ÿæˆå‘¨æŠ¥")
    default_prompt = "ç»™æˆ‘ç”Ÿæˆæœ¬å‘¨é¡¹ç›®å‘¨æŠ¥ï¼šæ€»ä½“è¿›åº¦ã€é‡Œç¨‹ç¢‘ã€Top é£é™©ã€æŒ‰è´Ÿè´£äººç»Ÿè®¡ã€ä¸‹å‘¨è¡ŒåŠ¨æ¸…å•ï¼ˆæŒ‰å…¬å¸æ¨¡æ¿è¾“å‡ºï¼‰ã€‚"
    user_request = st.text_area("è‡ªç„¶è¯­è¨€", value=default_prompt, height=120)

    gen = st.button("ğŸš€ ç”Ÿæˆå‘¨æŠ¥", type="primary", disabled=(df is None))

    if gen and df is not None:
        # Load skill pack (optional)
        skill_pack = None
        if skill_name != "None":
            skill_pack = load_skill_pack(skill_name)
            trace.append(f"Loaded skill pack: {skill_name}")

        # Compute KPIs locally (tool layer)
        kpis = compute_weekly_kpis(df)
        trace.append("Computed weekly KPIs")

        # Prepare compact context for LLM
        table_md = dataframe_to_markdown_table(df, max_rows=25)
        prompt = build_report_prompt(user_request, kpis, table_md, skill_pack)
        trace.append("Built LLM prompt")

        # Call local Ollama
        try:
            response_text = call_ollama_chat(
                host=ollama_host,
                model=ollama_model,
                system=prompt["system"],
                user=prompt["user"],
                temperature=temperature,
            )
            trace.append("Ollama chat completed")
        except Exception as e:
            st.error(f"è°ƒç”¨ Ollama å¤±è´¥ï¼š{e}")
            st.stop()

        st.markdown("### âœ… å‘¨æŠ¥è¾“å‡ºï¼ˆMarkdownï¼‰")
        st.markdown(response_text)

        # Downloads
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ Markdown",
            data=response_text.encode("utf-8"),
            file_name=f"weekly_report_{datetime.now().strftime('%Y%m%d_%H%M')}.md",
            mime="text/markdown",
        )

        # Optional DOCX
        docx_bytes = make_docx_from_markdown_text(response_text)
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ DOCXï¼ˆçº¯æ–‡æœ¬ç‰ˆï¼‰",
            data=docx_bytes,
            file_name=f"weekly_report_{datetime.now().strftime('%Y%m%d_%H%M')}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )

# ---- Trace ----
if show_trace:
    st.divider()
    st.subheader("æ‰§è¡Œè½¨è¿¹")
    st.code("\n".join([f"- {x}" for x in trace]) if trace else "- ï¼ˆç­‰å¾…æ“ä½œï¼‰")
